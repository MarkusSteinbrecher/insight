---
title: "Absence of validated, production-scale evidence for agentic AI enterprise architectures"
type: gap
confidence: high
sources:
  - source-001
  - source-002
  - source-003
tags:
  - evidence-gap
  - production-readiness
  - implementation
  - pilot-to-production
  - validation
created: 2026-02-14
---

## Insight

The most significant gap across all three sources is the absence of rigorous, production-scale evidence that agentic AI enterprise architectures deliver on their promises. Each source, in its own way, reveals this gap. Source 1 (Kumar) proposes an ambitious seven-layer agentic EA framework with compelling performance claims (96.3% threat detection, sub-200ms response times), but these results come from comparative analysis against baselines, not from production deployment in real enterprises. The case studies are illustrative, not empirical validations. Source 2 (Oaj et al.) is explicitly a work-in-progress prototype: the EKG-enhanced configuration matched only Level 1 capabilities, and the system has not been tested with real enterprise users or at scale. Source 3 (Economist Impact) provides the most damning data point: fewer than 20% of AI pilots make it to production, and only 37% of executives believe their GenAI applications are production-ready.

This creates a credibility gap in the field. The theoretical frameworks (Source 1) are sophisticated and architecturally sound, but they lack the empirical grounding that enterprise decision-makers require. The prototypes (Source 2) demonstrate feasibility but not scalability or reliability. The survey data (Source 3) confirms that the broader enterprise landscape is far from achieving the visions described in Sources 1 and 2. The chasm between architectural aspiration and operational reality is wide and largely unbridged.

This gap is compounded by the absence of failure case studies. None of the sources examines why agentic AI architectures fail in enterprise contexts, what the common failure modes are, or how organisations recover from failed implementations. Source 3's statistic that fewer than 20% of pilots reach production implies an 80%+ failure rate, but the causes are not systematically analyzed. Understanding failure patterns may be more valuable than understanding success frameworks for practitioners navigating this space.

## Evidence

- Source 1: Performance claims based on comparative analysis, not production deployment; case studies are illustrative scenarios, not longitudinal empirical studies.
- Source 2: Explicitly described as "work-in-progress"; EKG matching limited to Level 1 capabilities; no user testing or production validation reported.
- Source 3: Fewer than 20% of AI pilots reach production; only 37% of executives (29% of practitioners) believe GenAI applications are production-ready; only 22% have AI-ready architectures.
- Source 3: Revenue growth cited by only 19% as having contributed to the AI investment case, suggesting production-scale economic value is not yet being demonstrated.
- Source 1 cites that 65% of businesses report regularly using AI, but this statistic conflates experimental use with production deployment -- a distinction the field consistently blurs.
- No source provides longitudinal data on agentic EA implementations over time (e.g., 12-month or 24-month outcomes).

## Significance

This gap is the single most important finding for thought leadership positioning. It means that any organisation claiming to have a "proven" agentic AI enterprise architecture should be viewed with skepticism. It also means there is an enormous opportunity for research and content that bridges the aspiration-reality divide: practical implementation guides, failure mode analyses, realistic maturity models, and honest assessments of what is achievable today versus what remains aspirational. Content that acknowledges this evidence gap while providing actionable guidance for incremental progress will be more credible and useful than content that promotes visionary frameworks without addressing implementation reality.

## Questions to Explore

- What are the most common failure modes when enterprises attempt to implement agentic AI architectures?
- What does a realistic, evidence-based maturity model for agentic EA look like (from pilot to production to scale)?
- Which industries or use cases have the strongest evidence of production-scale agentic AI in enterprise contexts?
- What minimum viable architecture enables enterprises to move from experimentation to production with AI agents?
- How long does it typically take to move from agentic AI prototype to production deployment, and what are the key milestones?
- What would a rigorous longitudinal study of agentic EA implementation look like, and who is positioned to conduct one?
